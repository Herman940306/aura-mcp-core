# Home Server Deployment Guide - Zero Cloud Cost

**Target**: Run the entire Aura MCP stack on your home server with **$0/month** cloud costs.

---

## üè† Why Home Server?

| Feature | Cloud | Home Server |
|---------|-------|-------------|
| **Monthly Cost** | $230-750 | **$0** (electricity only) |
| **Data Privacy** | ‚ùå External | ‚úÖ Your hardware |
| **Latency** | 50-200ms | <10ms (local network) |
| **Scalability** | ‚úÖ Unlimited | Limited by hardware |
| **Control** | ‚ùå Vendor lock-in | ‚úÖ Full control |
| **Setup Complexity** | Low | Medium |

**Bottom Line**: Perfect for personal/home use, development, and privacy-focused deployments.

---

## üìã Prerequisites

### Hardware Requirements

| Component | Minimum | Recommended | Notes |
|-----------|---------|-------------|-------|
| **CPU** | 4 cores (i5/Ryzen 5) | 8+ cores (i7/Ryzen 7) | More cores = faster inference |
| **RAM** | 8GB | 16GB+ | 4GB models + 4GB Qdrant + 4GB OS |
| **Disk** | 50GB free | 100GB SSD | Models cache ~10GB, logs grow |
| **GPU** | None (optional) | NVIDIA 4GB+ VRAM | 5-10x speedup for embeddings |
| **Network** | 100 Mbps | 1 Gbps | For initial model downloads |

**Tested On**:

- ‚úÖ Ubuntu 22.04 LTS
- ‚úÖ Windows 11 with WSL2
- ‚úÖ macOS Ventura+
- ‚úÖ Debian 12
- ‚úÖ Raspberry Pi 4 (8GB) - works but slow

### Software Requirements

```bash
# Docker & Docker Compose
docker --version  # Should be 20.10+
docker compose version  # Should be 2.0+

# If not installed:
# Linux: https://docs.docker.com/engine/install/
# Windows: Docker Desktop
# macOS: Docker Desktop or Orbstack
```

---

## üöÄ Quick Start (5 Minutes)

### Step 1: Clone Repository

```bash
cd /home/youruser  # Or any directory
git clone https://github.com/yourusername/LATEST_MCP.git
cd LATEST_MCP
```

### Step 2: Configure Environment

```bash
# Copy environment template
cp .env.example .env

# Edit with your GitHub token (only external dependency)
nano .env
# or
code .env
```

Set your GitHub token:

```bash
GITHUB_TOKEN=ghp_your_token_here
```

**Get GitHub Token**: <https://github.com/settings/tokens> (needs `repo` scope)

### Step 3: Start All Services

```bash
# Build and start everything
docker compose up -d --build

# Watch logs (optional)
docker compose logs -f
```

**First Run**: Models will auto-download (~200MB, 2-5 minutes on fast connection)

### Step 4: Verify Services

```bash
# Check all services are healthy
docker compose ps

# Test endpoints
curl http://localhost:9101/health       # ML Backend
curl http://localhost:6333/healthz      # Qdrant
curl http://localhost:9100              # MCP Gateway

# Open dashboard in browser
open http://localhost:9102
```

**Expected Output**:

```
NAME            IMAGE                 STATUS          PORTS
mcp_gateway     ...                   Up (healthy)    0.0.0.0:9100->8000/tcp
mcp_ml_backend  ...                   Up (healthy)    0.0.0.0:9101->8001/tcp
mcp_qdrant      qdrant/qdrant:v1.11   Up (healthy)    0.0.0.0:6333->6333/tcp
mcp_dashboard   ...                   Up              0.0.0.0:9102->80/tcp
```

---

## üìä Architecture (What's Running Locally)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Your Home Server                          ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Gateway   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ML Backend  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Qdrant     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  :9100     ‚îÇ    ‚îÇ   :9101     ‚îÇ    ‚îÇ   :6333      ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ       ‚îÇ                  ‚îÇ                     ‚îÇ            ‚îÇ
‚îÇ       ‚îÇ                  ‚îÇ                     ‚îÇ            ‚îÇ
‚îÇ       ‚ñº                  ‚ñº                     ‚ñº            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ            Docker Network (mcp-network)             ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Volumes (Persistent Storage):                              ‚îÇ
‚îÇ  ‚Ä¢ backend-model-cache  (~200MB ML models)                  ‚îÇ
‚îÇ  ‚Ä¢ mcp-model-cache      (~200MB)                            ‚îÇ
‚îÇ  ‚Ä¢ qdrant-data          (your vector embeddings)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ Access from any device on your network:
         ‚îú‚îÄ Laptop: http://192.168.1.100:9100
         ‚îú‚îÄ Phone:  http://192.168.1.100:9102
         ‚îî‚îÄ Desktop: http://192.168.1.100:6333
```

---

## üîß Configuration Profiles

### Profile 1: Development (Week 1 - Baseline)

**Use Case**: Fast iteration, learning, testing

```bash
# In .env:
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DEVICE=cpu
RERANK_ENABLED=0
QUERY_EXPANSION_ENABLED=0
QDRANT_POOL_SIZE=1
```

**Resource Usage**:

- CPU: 20-30% (4-core system)
- RAM: ~4GB
- Disk: 50GB
- Latency: 15-25ms per query

**Restart to apply**:

```bash
docker compose down
docker compose up -d
```

---

### Profile 2: Staging (Week 2-3 - Quality Boost)

**Use Case**: Testing quality improvements, pre-production

```bash
# In .env:
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DEVICE=cpu
RERANK_ENABLED=1
RERANK_TOP_K=30
QUERY_EXPANSION_ENABLED=1
EXPANSION_STRATEGY=synonyms
QDRANT_POOL_SIZE=3
```

**Resource Usage**:

- CPU: 40-60%
- RAM: ~6GB
- Disk: 60GB
- Latency: 60-100ms per query

---

### Profile 3: Production (Week 5+ - Maximum Quality)

**Use Case**: Best quality, GPU acceleration

```bash
# In .env:
EMBEDDING_MODEL=all-mpnet-base-v2
EMBEDDING_DEVICE=cuda  # Requires NVIDIA GPU
RERANK_ENABLED=1
RERANK_MODEL=ms-marco-electra-base
RERANK_DEVICE=cuda
RERANK_TOP_K=50
QUERY_EXPANSION_ENABLED=1
EXPANSION_STRATEGY=multi_query
QDRANT_POOL_SIZE=10
```

**Resource Usage**:

- CPU: 20-30% (GPU offloaded)
- RAM: ~8GB
- GPU VRAM: 4GB+
- Disk: 100GB
- Latency: 25-50ms per query

**GPU Setup** (NVIDIA only):

```bash
# Install nvidia-docker2
sudo apt install nvidia-docker2
sudo systemctl restart docker

# Verify GPU is visible
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

---

## üåê Access From Other Devices

### Find Your Server's IP

```bash
# Linux/macOS
ip addr show | grep "inet 192"
# or
hostname -I

# Windows (PowerShell)
ipconfig | findstr IPv4
```

**Example Output**: `192.168.1.100`

### Access From Network

From any device on same WiFi/LAN:

```bash
# From laptop
curl http://192.168.1.100:9101/health

# From phone browser
http://192.168.1.100:9102

# From desktop
curl http://192.168.1.100:6333/healthz
```

### Port Forwarding (Access From Internet - Optional)

**‚ö†Ô∏è Security Warning**: Only do this if you understand the risks!

1. **Router Settings**:
   - Port forward `9100` ‚Üí `192.168.1.100:9100` (MCP Gateway)
   - Port forward `9102` ‚Üí `192.168.1.100:9102` (Dashboard)

2. **Add Authentication** (recommended):

   ```bash
   # Add nginx reverse proxy with basic auth
   # Or use Cloudflare Tunnel (free, secure)
   ```

3. **Use Dynamic DNS**:
   - NoIP (free)
   - DuckDNS (free)
   - Your home IP: `your-domain.ddns.net`

**Better Alternative**: Use Tailscale or Wireguard VPN (free, secure)

---

## üìà Monitoring (Optional, Still Free)

### Enable Prometheus + Grafana

Uncomment in `docker-compose.yml`:

```yaml
# Remove # from these services:
  prometheus:
    # ... (already in file)

  grafana:
    # ... (already in file)
```

```bash
# Restart stack
docker compose down
docker compose up -d

# Access monitoring
open http://localhost:9090  # Prometheus
open http://localhost:3000  # Grafana (admin/admin)
```

### Pre-built Dashboards

Import these JSON files (create if needed):

**Wave 6 Metrics Dashboard**:

```bash
# Create monitoring/grafana/dashboards/wave6.json
# (See WAVE6_DEPLOYMENT.md for dashboard JSON)
```

---

## üõ†Ô∏è Maintenance

### Update Models

```bash
# Models auto-update on container rebuild
docker compose pull
docker compose up -d --build
```

### View Logs

```bash
# All services
docker compose logs -f

# Specific service
docker compose logs -f gateway
docker compose logs -f ml-backend

# Last 100 lines
docker compose logs --tail=100 gateway
```

### Backup Data

```bash
# Backup Qdrant data
docker compose exec qdrant tar czf /tmp/qdrant-backup.tar.gz /qdrant/storage
docker cp mcp_qdrant:/tmp/qdrant-backup.tar.gz ./backups/

# Backup environment
cp .env .env.backup

# Backup logs
tar czf logs-backup-$(date +%Y%m%d).tar.gz logs/
```

### Restore Data

```bash
# Stop services
docker compose down

# Restore Qdrant volume
docker volume rm latest_mcp_qdrant-data
docker volume create latest_mcp_qdrant-data
docker run --rm -v latest_mcp_qdrant-data:/qdrant/storage \
  -v $(pwd)/backups:/backup ubuntu \
  tar xzf /backup/qdrant-backup.tar.gz -C /

# Start services
docker compose up -d
```

### Clean Up

```bash
# Remove stopped containers
docker compose down

# Remove all data (CAUTION!)
docker compose down -v

# Clean unused images/volumes
docker system prune -a
```

---

## üîí Security Best Practices

### 1. Firewall Rules

```bash
# Linux (UFW)
sudo ufw allow 22/tcp    # SSH
sudo ufw allow 9100/tcp  # MCP Gateway (if exposing)
sudo ufw deny 6333/tcp   # Block Qdrant from internet
sudo ufw deny 9101/tcp   # Block backend from internet
sudo ufw enable

# Check status
sudo ufw status
```

### 2. Environment Secrets

```bash
# Never commit .env to git
echo ".env" >> .gitignore

# Use strong passwords
GRAFANA_PASSWORD=$(openssl rand -base64 32)
```

### 3. Network Isolation

```bash
# Keep services on private network
# Only expose gateway (9100) if needed
# Use VPN for remote access (Tailscale/Wireguard)
```

### 4. Regular Updates

```bash
# Weekly updates
docker compose pull
docker compose up -d --build
apt update && apt upgrade -y  # Update host OS
```

---

## üêõ Troubleshooting

### Service Won't Start

```bash
# Check logs
docker compose logs gateway

# Common issues:
# 1. Port already in use
sudo netstat -tulpn | grep 9100
sudo kill <pid>

# 2. Out of disk space
df -h
docker system prune -a

# 3. Out of memory
free -h
# Add swap or reduce QDRANT_POOL_SIZE
```

### Models Won't Download

```bash
# Check internet connection
curl -I https://huggingface.co

# Pre-download models manually
docker compose exec ml-backend python -c "
from sentence_transformers import SentenceTransformer
SentenceTransformer('all-MiniLM-L6-v2')
"

# Check disk space
docker system df
```

### Slow Performance

```bash
# Check resource usage
docker stats

# Reduce pool size
QDRANT_POOL_SIZE=1

# Disable features
RERANK_ENABLED=0
QUERY_EXPANSION_ENABLED=0

# Add more RAM or CPU cores
```

### Can't Access From Other Devices

```bash
# Check firewall
sudo ufw status

# Check Docker network
docker network inspect latest_mcp_mcp-network

# Verify IP binding (should be 0.0.0.0, not 127.0.0.1)
docker compose ps
```

### GPU Not Working

```bash
# Verify NVIDIA drivers
nvidia-smi

# Install nvidia-docker2
sudo apt install nvidia-docker2
sudo systemctl restart docker

# Test GPU in container
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi

# If still failing, use CPU
EMBEDDING_DEVICE=cpu
RERANK_DEVICE=cpu
```

---

## üìä Performance Benchmarks

### Home Server Examples

| Hardware | Profile | Latency (p95) | QPS | Cost |
|----------|---------|---------------|-----|------|
| **Raspberry Pi 4 (8GB)** | Development | 800ms | 1-2 | $75 (one-time) |
| **Intel i5-12400 + 16GB** | Staging | 100ms | 10-20 | $400 (one-time) |
| **Ryzen 7 5800X + 32GB** | Production (CPU) | 60ms | 30-50 | $800 (one-time) |
| **i7-12700K + RTX 3080** | Production (GPU) | 30ms | 100+ | $1500 (one-time) |

**Cloud Equivalent**: $230-750/month = $2,760-9,000/year

**Break-even**: 2-4 months for mid-range, 6-18 months for high-end

---

## üéØ Next Steps

### Week 1: Get Baseline Running

- ‚úÖ Docker Compose up
- ‚úÖ Verify all services healthy
- ‚úÖ Access dashboard from network
- ‚úÖ Run test queries

### Week 2: Enable Re-Ranking

- Set `RERANK_ENABLED=1` in `.env`
- Restart: `docker compose up -d`
- Monitor latency increase
- Verify quality improvement

### Week 3-4: Full Strategy

- Set `QUERY_EXPANSION_ENABLED=1`
- Monitor end-to-end performance
- Tune based on your hardware

### Week 5+: Optimize & Scale

- Add GPU if available
- Enable monitoring (Prometheus/Grafana)
- Fine-tune pool sizes
- Consider k3s for multi-node

---

## üìû Support

**Issues**: <https://github.com/yourusername/LATEST_MCP/issues>

**Community**:

- Discord: (add your link)
- Reddit: r/homelab

**Documentation**:

- [WAVE6_DEPLOYMENT.md](./WAVE6_DEPLOYMENT.md) - Full deployment guide
- [README.md](../README.md) - Configuration reference
- [PROJECT_STATE_OVERVIEW.md](./PROJECT_STATE_OVERVIEW.md) - System architecture

---

## üéâ You're Done

You now have a **$0/month enterprise-grade AI stack** running on your home server with:

‚úÖ Production-quality retrieval
‚úÖ Zero cloud costs
‚úÖ Full data privacy
‚úÖ Sub-10ms latency on local network
‚úÖ Unlimited queries (only limited by your hardware)

**Welcome to self-hosted AI!** üè†ü§ñ
